slurm_params:
  job-name: "concept_decomposition"
  account: "gpu-research"
  output: "slurmlog.out" # redirect stdout
  error: "slurmlog.err" # redirect stderr
  partition: killable # (see resources section)
  time: "1440" # max time (minutes)
  # time: "30" # max time (minutes)
  signal: "USR1@120" # how to end job when timeï¿½s up
  nodes: "1" # number of machines
  ntasks: "1" # number of processes
  mem: "24000" # CPU memory (MB)
  cpus-per-task: "8" # CPU cores per process
  gpus: "1" # GPUs in tota
  # constraint: "a6000"
  # constraint: "a6000|geforce_rtx_3090"
  constraint: "a6000"

train_params:
  train_data_dir: "input_concepts"       # Directory containing the training data
  parent_data_dir: "cat_sculpture"            # Subdirectory within train_data_dir
  node: "v0"                            # Node to process (e.g., v0, v1)
  test_name: "textual_inversion_test"   # Name for the test
  max_train_steps: 1000                 # Maximum number of training steps
  validation_steps: 100                 # Number of steps between validations
  placeholder_token: "<*> <&>"          # Placeholder tokens for textual inversion
  validation_prompt: "<*>,<&>,<*> <&>"  # Validation prompt
  seed: 12345421                              # Random seed for reproducibility            # Device type (cuda or cpu)

cache_dir: '/vol/scratch/jonathany2/cache'
command: "/home/ML_courses/03683533_2024/jonathan_ido_or/concept_decomposition/run_main"
run_name: "textual_inversion_test"
